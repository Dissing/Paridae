// Copyright (c) 2018 Lasse Dissing
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at http://mozilla.org/MPL/2.0/.


//C headers

//stdlib.h
malloc :: (size: u64) -> *void
calloc :: (num: u64, size: u64) -> *void
realloc :: (ptr: *void, new_size: u64) -> *void
free :: (ptr: *void)

exit :: (status: int)

//stdio.h

fopen :: (filename: *u8, mode: *u8) -> *void
fclose :: (stream: *void)

fseek :: (stream: *void, offset: u64, origin: s32) -> s32
ftell :: (stream: *void) -> u64
rewind :: (stream: *void)

fread :: (ptr: *void, size: u64, count: u64, fp: *void) -> u64

putchar :: (ch: s32) -> s32
getchar :: () -> s32

//string.h

strlen :: (str: *u8) -> u64
strcmp :: (lhs: *u8, rhs: *u8) -> s32
strncmp :: (lhs: *u8, rhs: *u8, num: u64) -> s32
memcpy :: (dst: *void, src: *void, len: u64) -> *void

//stdlib

null : *u8 = 0;

_paridae_slice :: struct {
  ptr : *u8,
  len : s32,
}

len :: (slice: _paridae_slice) -> s32 {
  return slice.len;
}

make :: (size: u64) -> []u8 {
  p : *u8 = cast(*u8, malloc(size));
  slice : _paridae_slice;
  slice.ptr = p;
  slice.len = size;
  return slice;
}

delete :: (slice: []u8) {
  p_slice : _paridae_slice = cast([]u8, slice);
  free(p_slice.ptr);
}

c_str :: (s: []s8) -> *s8 {
  raw : _paridae_slice = cast(_paridae_slice, s);
  return cast(*s8, raw.ptr);
}

is_alphabetic :: (c: u8) -> bool {
  return (c >= 65 && c <= 90) || (c >= 97 && c <= 122);
}

is_digit :: (c: u8) -> bool {
  return c >= 48 && c <= 57;
}

is_alphanumeric :: (c: u8) -> bool {
  return is_alphabetic(c) || is_digit(c);
}

//HashMap

HashMap :: struct {
  keys: []*void,
  values: []*void,
  size: u64,
  load: u64,
}

hashmap_create :: (size: u64) -> *HashMap {
  map : *HashMap = malloc(sizeof(HashMap));

  map.size = size;
  map.keys = cast([]u64, make(size*8));
  map.values = cast([]*void, make(size*8));

  return map;
}

hashmap_hash :: (key: *void) -> u64 {
  ad : u64 = cast(u64, key);
  return (ad ^ (ad >> 16));
}

hashmap_insert :: (map: *HashMap, key: *void, value: *void) {
  h : u64 = hashmap_hash(key) % map.size;
  if map.load + 1 >= map.size {
    printf("Hashmap of size %lu is full!\n", map.size);
    exit(-1);
  }
  while (true) {
    if (map.keys[h] == key)  break;
    if (map.keys[h] == null) {
      map.keys[h] = key;
      map.values[h] = value;
      map.load = map.load + 1;
    } else {
      h = (h + 1) % map.size;
    }
  }
}

hashmap_lookup :: (map: *HashMap, key: *void) -> *void {
  h : u64 = hashmap_hash(key) % map.size;
  while (true) {
    if (map.keys[h] == key)  return map.values[h];
    if (map.keys[h] == null)  return null;
    h = (h + 1) % map.size;
  }
}

hashmap_destroy :: (map: *HashMap) {

}

//Tokens

TokenType :: enum {
    Invalid,
    Identifier,
    Directive,
    EOF,
    //Keywords
    Break,
    Cast,
    Const,
    Continue,
    Defer,
    Enum,
    Else,
    For,
    If,
    Return,
    Struct,
    Union,
    While,
    //Operators and punctuation
    Plus,
    Minus,
    Star,
    Slash,
    Percent,
    LessLess,
    GreaterGreater,
    And,
    AndAnd,
    Or,
    OrOr,
    Hat,
    Equal,
    Bang,
    BangEqual,
    EqualEqual,
    Less,
    Greater,
    LessEqual,
    GreaterEqual,
    LeftParen,
    RightParen,
    LeftBracket,
    RightBracket,
    LeftCurly,
    RightCurly,
    Comma,
    Dot,
    Colon,
    ColonColon,
    Semicolon,
    Arrow,
    //Literals
    Integer,
    Float,
    String,
    True,
    False,
}

Token :: struct {
  type: TokenType,
  position: u32,
  lexeme: *u8,
}


//Lexer


LexingContext :: struct {
  start: u64,
  current: u64,
  line: u64,
  source: *u8,
  source_len: u64,
  tokens: []Token,
  current_token_idx: u64,
}

is_done_lexing :: (ctx: *LexingContext) -> bool {
  return ctx.current >= ctx.source_len;
}

peek_token :: (ctx: *LexingContext, offset: u64) -> u8 {
  if is_done_lexing(ctx) return 0;
  return ctx.source[ctx.current + offset];
}

advance :: (ctx: *LexingContext) -> u8 {
  ctx.current = ctx.current + 1;
  return ctx.source[ctx.current - 1];
}

add_simple_token :: (ctx: *LexingContext, token_type: TokenType) {
  token : *Token = &ctx.tokens[ctx.current_token_idx];
  token.type = token_type;
  token.lexeme = null;
  token.position = ctx.line;
  ctx.current_token_idx = ctx.current_token_idx + 1;
}

add_lookahead_conditional_token :: (ctx: *LexingContext, expect: u8, first: TokenType, second: TokenType) {
  token : *Token = &ctx.tokens[ctx.current_token_idx];
  token.lexeme = null;
  token.position = ctx.line;
  if peek_token(ctx,0) == expect {
    advance(ctx);
    token.type = first;
  } else {
    token.type = second;
  }
  ctx.current_token_idx = ctx.current_token_idx + 1;
}

get_lexeme :: (ctx: *LexingContext) -> *u8 {
  str_len: u64 = ctx.current - ctx.start;
  str: *u8 = malloc(str_len + 1);
  memcpy(str, &ctx.source[ctx.start], str_len);
  str[str_len] = 0;
  return str;
}

add_lexeme_token :: (ctx: *LexingContext, lexeme: *u8, token_type: TokenType) {
  token : *Token = &ctx.tokens[ctx.current_token_idx];
  token.type = token_type;
  token.lexeme = lexeme;
  token.position = ctx.line;
  ctx.current_token_idx = ctx.current_token_idx + 1;
}

single_line_comment :: (ctx: *LexingContext) {
  while (peek_token(ctx, 0) != 10 && !is_done_lexing(ctx)) advance(ctx);
}

is_keyword :: (s: *u8) -> TokenType {
  //TODO Replace this with a hashtable or at least a match

  if !strcmp(s, "break")  return Break;
  if !strcmp(s, "cast")  return Cast;
  if !strcmp(s, "continue")  return Continue;
  if !strcmp(s, "defer")  return Defer;
  if !strcmp(s, "enum")  return Enum;
  if !strcmp(s, "else")  return Else;
  if !strcmp(s, "false")  return False;
  if !strcmp(s, "for")  return For;
  if !strcmp(s, "if")  return If;
  if !strcmp(s, "return")  return Return;
  if !strcmp(s, "struct")  return Struct;
  if !strcmp(s, "union")  return Union;
  if !strcmp(s, "true")  return True;
  if !strcmp(s, "while")  return While;
  return Invalid;
}

lex_string :: (ctx: *LexingContext) {

  start_line : u64 = ctx.line;
  
  while peek_token(ctx, 0) != 34 && !is_done_lexing(ctx) {
    if peek_token(ctx, 0) == 10  ctx.line = ctx.line + 1;
    advance(ctx);
  }

  if is_done_lexing(ctx) {
    printf("Unterminated string starting on line %lu", start_line);
    exit(-1);
  }

  //Consume closing "
  advance(ctx);

  lexeme : *u8 = get_lexeme(ctx);
  add_lexeme_token(ctx, lexeme, String);
}

lex_number :: (ctx: *LexingContext) {

  while is_digit(peek_token(ctx,0))  advance(ctx);
  dot_encountered : bool = false;
  if peek_token(ctx,0) == 46 && is_digit(peek_token(ctx,1)) {
    dot_encountered = true;
    advance(ctx);
    while is_digit(peek_token(ctx,0))  advance(ctx);
  }

  lexeme : *u8 = get_lexeme(ctx);
  t : TokenType; 
  if dot_encountered  t = Float;
  else  t = Integer;

  add_lexeme_token(ctx, lexeme, t);
}

lex_identifier :: (ctx: *LexingContext) {
  while (is_alphanumeric(peek_token(ctx, 0)) || peek_token(ctx, 0) == 95) advance(ctx);
  lexeme : *u8 = get_lexeme(ctx);
  keyword : TokenType = is_keyword(lexeme);
  if keyword != Invalid add_simple_token(ctx, keyword);
  else add_lexeme_token(ctx, lexeme, Identifier);
}

scan_token :: (ctx: *LexingContext) {
  c : u8 = advance(ctx);

  //TODO Implement char literals such that we can replace the raw ASCII values here
  //TODO A match statement would also be quite nice here
  if c == 40 add_simple_token(ctx, LeftParen);
  else if c == 41 add_simple_token(ctx, RightParen);
  else if c == 91 add_simple_token(ctx, LeftBracket);
  else if c == 93 add_simple_token(ctx, RightBracket);
  else if c == 123 add_simple_token(ctx, LeftCurly);
  else if c == 125 add_simple_token(ctx, RightCurly);
  else if c == 43 add_simple_token(ctx, Plus);
  else if c == 42 add_simple_token(ctx, Star);
  else if c == 37 add_simple_token(ctx, Percent);
  else if c == 94 add_simple_token(ctx, Hat);
  else if c == 59 add_simple_token(ctx, Semicolon);
  else if c == 46 add_simple_token(ctx, Dot);
  else if c == 44 add_simple_token(ctx, Comma);
  else if c == 45 add_lookahead_conditional_token(ctx, 63, Arrow, Minus);
  else if c == 58 add_lookahead_conditional_token(ctx, 58, ColonColon, Colon);
  else if c == 61 add_lookahead_conditional_token(ctx, 61, EqualEqual, Equal);
  else if c == 33 add_lookahead_conditional_token(ctx, 61, BangEqual, Bang);
  else if c == 38 add_lookahead_conditional_token(ctx, 38, AndAnd, And);
  else if c == 124 add_lookahead_conditional_token(ctx, 38, OrOr, Or);
  else if c == 60 {
     n1 : u8 = peek_token(ctx, 0);
     if n1 == 60 {advance(ctx); add_simple_token(ctx, LessLess);}
     else if n1 == 61 {advance(ctx); add_simple_token(ctx, LessEqual);}
     else add_simple_token(ctx, Less);
  }
  else if c == 62 {
     n2 : u8 = peek_token(ctx, 0);
     if n2 == 62 {advance(ctx); add_simple_token(ctx, GreaterGreater);}
     else if n2 == 61 {advance(ctx); add_simple_token(ctx, GreaterEqual);}
     else add_simple_token(ctx, Less);
  }
  else if c == 47 {
    if peek_token(ctx, 0) == 47 single_line_comment(ctx);
    else add_simple_token(ctx, Slash);
  }
  else if c == 32 || c ==  9 {}
  else if c == 10 ctx.line = ctx.line + 1;
  else if c == 34 lex_string(ctx);
  else {
    if is_digit(c) lex_number(ctx);
    else if (is_alphabetic(c) || c == 95) lex_identifier(ctx);
    else {
      printf("Unexpected character %c = %d on line %lu\n", c, c, ctx.line);
      exit(-1);
    }
  }
}

NUM_TOKENS : u32 = sizeof(Token) * 1024 * 1024;

lex :: (source: *u8, source_len: u64) -> []Token {

  tokens : []Token = cast([]Token, make(NUM_TOKENS));

  ctx : *LexingContext = cast(*LexingContext, malloc(sizeof(LexingContext)));
  ctx.source = source;
  ctx.source_len = source_len;
  ctx.start = 0;
  ctx.current = 0;
  ctx.line = 1;
  ctx.tokens = tokens;
  ctx.current_token_idx = 0;
  
  while !is_done_lexing(ctx) {
    ctx.start = ctx.current;
    scan_token(ctx);
    if ctx.current_token_idx >= NUM_TOKENS {
      printf("Ran out of token storage!\n");
      break;
    }
  }

  free(ctx);

  return tokens;
}

//AST

//Forward declarations

AstType :: struct {}
Expr :: struct {}
Stmt :: struct {}
Item :: struct {}
Block :: struct {}

IntegerSize :: enum {
  I8,
  I16,
  I32,
  I64,
  Int_Arch,
  Int_Unspecified,
}

FloatingSize :: enum {
  F32,
  F64,
  Float_Unspecified,
}

AstTypeKind :: enum {
  Type_Bool,
  Type_Signed,
  Type_Unsigned,
  Type_Float,
  Type_Char,
  Type_Array,
  Type_Slice,
  Type_Ptr,
  Type_Void,
  Type_Function,
  Type_Struct,
  Type_Union,
  Type_Enum,
  Type_Infer,
}

AstTypeNode :: union {
  integer: IntegerSize,
  floating: FloatingSize,
  slice: *AstType,
  ptr: *AstType,
  function: *AstType,
  _struct: *AstType,
  _union: *AstType,
  _enum: *AstType,
}

AstType :: struct {
  tag: AstTypeKind,
  node: AstTypeNode,
}

LiteralKind :: enum {
  Lit_Int,
  Lit_Float,
  Lit_Bool,
  Lit_Str,
}

LiteralValue :: union {
  floating: f64,
  integer: u64,
  boolean: bool,
  str: *u8,
}

Literal :: struct {
  tag: LiteralKind,
  val: LiteralValue,
}


UnaryOperatorKind :: enum {
  // "*" operator for dereferencing pointers
  UnaryDeref,
  // "&" operator for taking the address of a place
  UnaryRefer,
  // "-" operator for numerical negation
  UnaryNegation,
  // "!" for logical not
  UnaryComplement,
}

BinaryOperatorKind :: enum {
  //Aritmetic operators
  Bin_Addition,
  Bin_Subtraction,
  Bin_Product,
  Bin_Division,
  Bin_Modulus,

  //Comperative operators
  Bin_Less,
  Bin_LessEq,
  Bin_Greater,
  Bin_GreaterEq,
  Bin_Equality,
  Bin_NotEq,

  //Bitwise operators
  Bin_BAnd,
  Bin_BOr,
  Bin_BXor,
  Bin_LeftShift,
  Bin_RightShift,

  //Logical operators
  Bin_And,
  Bin_Or,
}

BinaryExpr :: struct {
  operator: BinaryOperatorKind,
  left: *Expr,
  right: *Expr,
}

CastExpr :: struct {
  target_type: AstType,
  inner: *Expr,
}

CallExpr :: struct {
  func: *Expr,
  args: []Expr,
}

ConditionalExpr :: struct {
  condition: *Expr,
  then: *Block,
  otherwise: *Block,
}

IndexingExpr :: struct {
  array: *Expr,
  index: *Expr,
}

FieldExpr :: struct {
  strct: *Expr,
  field_name: *u8,
}

UnaryExpr :: struct {
  operator: UnaryOperatorKind,
  inner: *Expr,
}

ExprNode :: union {
  binary: BinaryExpr,
  _cast: CastExpr,
  call: CallExpr,
  identifier: *u8,
  conditional: ConditionalExpr,
  index: IndexingExpr,
  literal: Literal,
  field: FieldExpr,
  unary: UnaryExpr,
}

ExprKind :: enum {
  Expr_Binary,
  Expr_Cast,
  Expr_Call,
  Expr_Identifier,
  Expr_Conditional,
  Expr_Indexing,
  Expr_Literal,
  Expr_Field,
  Expr_Unary,
}

Expr :: struct {
  tag: ExprKind,
  node: ExprNode,
}


AssignmentStmt :: struct {
  lhs: *Expr,
  rhs: *Expr,
}

WhileStmt :: struct {
  condition: *Expr,
  body: *Block,
}

StmtNode :: union {
  assignment: AssignmentStmt,
  item: *Item,
  expr: *Expr,
  _return: *Expr,
  _defer: *Expr,
  _while: WhileStmt,
}

StmtKind :: enum {
  Stmt_Assignment,
  Stmt_Item,
  Stmt_Expr,
  Stmt_Return,
  Stmt_Break,
  Stmt_Continue,
  Stmt_Defer,
  Stmt_While,
  Stmt_Empty,
}

Stmt :: struct {
  tag: StmtKind,
  node: StmtNode,
}

Block :: struct {
  stmts: []Stmt,
}

Signature :: struct {
  input_types: []AstType,
  input_name: []*u8,
  output: AstType,
}

FunctionDecl :: struct {
  signature: Signature,
  block: *Block,
}

VariableDecl :: struct {
  type: AstType,
  value: *Expr,
}

ItemKind :: union {
  function: FunctionDecl,
  variable: VariableDecl,
  _struct: AstType,
  _union: AstType,
  _enum: AstType,
}

Item :: struct {
  name: *u8,
  node: ItemKind,
}

//Parser

ParsingContext :: struct {
  current_token: u64,
  tokens: []Token,
  items: []Item,
}

NUM_ITEMS : u64 = 1024*1024;

is_done_parsing :: (ctx: *ParsingContext) -> bool {
  return ctx.current_token == len(ctx.tokens);
}

accept :: (ctx: *ParsingContext, token: TokenType) -> bool {
  tok : Token = ctx.tokens[ctx.current_token];
  if !is_done_parsing(ctx) && tok.type == token {
    ctx.current_token = ctx.current_token + 1;
    return true;
  }
  return false;
}

expect :: (ctx: *ParsingContext, token: TokenType) -> bool {
  if accept(ctx, token) {
    return true;
  } else {
    tok : Token = ctx.tokens[ctx.current_token];
    printf("Expected %d but got %d\n on line %d", token, tok.type, tok.position);
    exit(-1);
  }
}

look_ahead :: (ctx: *ParsingContext, offset: u64) -> Token {
  if ctx.current_token == len(ctx.tokens) {
    eof_tok : Token;
    eof_tok.type = EOF;
    return eof_tok;
  } else  return ctx.tokens[ctx.current_token + offset];
}

consume :: (ctx: *ParsingContext) -> Token {
  ctx.current_token = ctx.current_token + 1;
  return ctx.tokens[ctx.current_token - 1];
}

parse_type :: (ctx: *ParsingContext) -> AstType {
  node: AstTypeNode;
  kind: AstTypeKind;

  token: Token = consume(ctx);
  if token.type == Identifier {
    ??
  } else if token.type == Star {
    inner: Type = consume(ctx);
    kind = Type_Ptr;
    
  }

  
  type: AstType;
}

parse_variable_decl :: (ctx: *ParsingContext) -> Item {
  identifier : Token = consume(ctx);
  expect(ctx, Colon);


  var_decl: VariableDecl;
 
  if accept(ctx, Equal)  var_decl.type = Type_Infer;
  else  var_decl.type = parse_type(ctx);

  if accept(ctx, Equal)  var_decl.expr = parse_expression(ctx, 0);
  else  var_decl.expr = null;

  item: Item;
  item.name = identifier.lexeme;
  kind: ItemKind;
  kind.variable = var_decl;
  return item;
}

parse_item :: (ctx: *ParsingContext) -> Item {
  token : Token = look_ahead(ctx, 0);
  if token.type != Identifier {
    printf("Tried to parse an item starting with a %d on line %d\n", token.type, token.position);
    exit(-1);
  }

  result : Item;

  look1 : Token = look_ahead(ctx, 1);
  if look1.type == Colon  result = parse_variable_decl(ctx);
  else if look1.type == ColonColon {
    look2 : Token = look_ahead(ctx, 2); 
    if look2.type == Enum  parse_enum_decl(ctx);
    else if look2.type == Struct  parse_struct_decl(ctx);
    else if look2.type == Union  parse_union_decl(ctx);
    else if look2.type == LeftParen  parse_function_decl(ctx);
    else {
      printf("Unexpected token %d in item on line %d", look2.type, token.position);
      exit(-1);
    }
  }
  else {
    printf("Unexpected token %d in item on line %d", look1.type, token.position);
    exit(-1);
  }
}

parse :: (tokens: []Token) -> []Item {
  items : []Item = cast([]Item, make(NUM_ITEMS*sizeof(Item)));
  ctx : *ParsingContext = malloc(sizeof(ParsingContext));
  ctx.current_token = 0;
  ctx.tokens = tokens;
  ctx.items = items;

  i : int = 0;
  while !is_done_parsing(ctx) {
    items[i] = parse_item(ctx);
    i = i +1;
    if i == NUM_ITEMS {
      printf("Ran out of storage of items!\n");
      break;
    }
  }

  free(ctx);
  return items;
}

//Driver

_paridae_entry :: () -> s32 {

  fp: *void = fopen("src/compiler.par", "r");

  if !fp {
    return -1;
  }

  //Determine file size by seeking to the end of the file
  fseek(fp, 0, 2); //SEEK_END = 2
  filesize : u64 = ftell(fp);
  rewind(fp);

  source : *u8 = cast(*u8, malloc(filesize));

  fread(source, filesize, 1, fp);

  tokens : []Token = lex(source, filesize);

  items : []Item = parse(tokens);

  delete(tokens);
  delete(items);

  fclose(fp);
  
  return 0;
}